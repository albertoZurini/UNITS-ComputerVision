{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /home/alberto/.cache/torch/hub/v0.10.0.zip\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /home/alberto/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
      "100%|██████████| 13.6M/13.6M [00:02<00:00, 5.44MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): ConvBNActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.1052e+00, -1.7308e+00, -2.2278e+00, -2.9621e+00, -2.3761e+00,\n",
      "         9.8064e-01, -1.5995e+00,  3.6929e+00,  6.3844e+00, -1.2970e+00,\n",
      "        -6.7583e+00, -3.3542e+00, -7.9624e+00, -4.4576e+00, -5.6436e+00,\n",
      "        -4.6615e+00, -1.9582e+00, -3.5506e-01, -1.2781e+00, -4.6722e+00,\n",
      "        -3.2885e+00, -2.5688e+00, -2.4332e+00, -1.3037e+00, -3.2455e+00,\n",
      "        -1.4179e+00, -1.1920e+00,  4.1882e-01, -1.6033e+00,  1.5931e+00,\n",
      "         2.8403e-01, -6.2212e-01, -2.9329e-01, -3.8180e+00, -1.5392e+00,\n",
      "        -2.8921e+00, -5.6117e-01, -2.3876e+00, -3.3341e-01,  1.2811e+00,\n",
      "        -1.2503e+00, -2.6462e+00, -3.0978e+00, -2.2449e+00, -4.4174e-01,\n",
      "        -1.2649e+00,  8.3433e-01, -2.0431e+00, -6.6184e-01, -8.3060e-02,\n",
      "         4.9313e-01, -1.7198e+00, -7.7386e-01, -1.0981e+00, -5.3155e-01,\n",
      "        -2.9183e+00, -1.9303e+00, -2.7204e+00, -6.0153e-01, -1.6766e+00,\n",
      "         1.3525e+00, -4.2070e+00, -1.4710e+00, -4.5550e+00, -3.2666e+00,\n",
      "        -4.0032e+00,  1.5984e-01, -1.9871e+00, -7.4311e-01, -4.2195e+00,\n",
      "        -3.8868e+00, -9.4489e-01, -2.1408e+00, -3.5596e+00, -2.4630e+00,\n",
      "        -3.2353e+00, -3.1423e+00, -2.6804e+00, -3.4393e-01,  1.3068e+00,\n",
      "        -1.8118e+00, -6.9335e-01,  6.1435e-01,  1.0630e+00,  7.0654e-01,\n",
      "        -2.1366e+00, -8.3014e-01, -1.2750e+00, -2.9467e+00,  2.6202e+00,\n",
      "        -3.0859e+00, -3.9255e+00, -5.0973e+00, -2.6906e+00, -4.2549e+00,\n",
      "        -5.7524e+00, -1.4606e+00, -3.3354e+00, -5.1130e+00,  1.3385e-01,\n",
      "         6.4464e-01, -3.8257e+00, -6.0627e-01, -3.8199e+00,  8.3392e+00,\n",
      "        -2.1287e-01,  1.5722e+00, -3.2494e+00, -1.3054e+00, -4.3483e+00,\n",
      "        -1.8965e+00, -4.4546e+00, -2.6056e+00, -4.7698e-01,  6.6775e-01,\n",
      "        -1.1096e+00, -1.9855e+00, -2.9817e+00,  6.5342e-02, -3.8773e-02,\n",
      "        -4.9824e+00, -3.5692e-01,  6.7643e-02,  2.7921e-02,  1.0628e+00,\n",
      "        -3.7482e+00, -2.2739e+00, -1.1246e+00, -3.6531e+00, -1.0111e+00,\n",
      "        -3.8168e+00, -2.6174e+00,  8.1445e-01, -4.8417e+00, -1.7767e-01,\n",
      "        -3.7808e+00, -2.7949e+00, -4.0459e+00, -2.7579e+00, -7.6127e+00,\n",
      "        -6.3265e+00, -3.7485e+00, -4.7905e+00, -2.9561e+00, -1.1666e+00,\n",
      "        -1.1429e+00,  4.1272e-01, -2.1647e+00, -2.2827e+00, -1.6735e+00,\n",
      "        -2.3965e+00,  6.1502e+00,  6.3246e+00,  4.1138e+00,  5.7698e+00,\n",
      "         1.3937e+00,  3.2599e-01,  8.0268e+00,  1.5777e+00, -1.7187e-02,\n",
      "         2.6953e-02, -7.5227e-01,  4.9768e-01, -1.5532e+00, -2.2914e+00,\n",
      "        -3.6449e+00, -6.5135e-01, -2.2577e+00,  1.5741e-01,  4.5923e+00,\n",
      "         3.3956e+00,  6.8798e-02, -1.5575e+00,  5.0127e+00,  5.8426e+00,\n",
      "         1.5394e+00, -2.0553e+00,  2.4105e+00, -2.4813e+00,  1.2902e+00,\n",
      "         1.9281e+00, -2.7946e+00,  1.2892e+00,  2.8270e-01,  2.5243e+00,\n",
      "         4.3552e+00,  5.6346e+00, -6.1317e-01,  3.3489e+00, -2.8114e-01,\n",
      "         2.3403e+00, -1.3421e+00,  5.4917e+00,  4.5105e+00,  2.5962e-01,\n",
      "         1.1464e+00, -1.2750e-01,  1.1116e+00,  5.9679e-02,  6.5217e+00,\n",
      "         2.4627e+00,  4.8651e-01, -3.3907e-01,  9.2139e+00,  1.6381e+00,\n",
      "         1.3135e+00,  1.9600e-01,  4.5599e+00,  2.1836e+00,  2.1914e-01,\n",
      "        -2.4134e+00,  5.9768e-01,  3.0017e+00, -5.4700e-01, -1.3011e+00,\n",
      "         2.8043e+00,  1.9621e+00,  2.0557e+00,  7.6501e-01,  1.6848e+00,\n",
      "         1.9434e+00, -7.9356e-01,  7.2037e+00,  9.0075e+00,  8.0023e+00,\n",
      "         2.3508e+00,  3.7506e+00,  5.7373e+00,  3.8043e+00,  6.5449e+00,\n",
      "         9.7195e+00,  1.0009e+01,  9.5279e+00,  2.3866e+00, -5.0577e-01,\n",
      "         5.1067e+00,  5.7260e-01,  1.5478e+00,  1.2804e+00,  3.5585e+00,\n",
      "         2.5420e+00,  1.4842e+00, -8.1669e-01, -2.7484e+00,  8.6007e-01,\n",
      "        -5.8432e-01, -4.1278e-01,  3.2600e+00,  9.6742e+00,  8.9915e+00,\n",
      "         9.2582e+00,  1.4001e+00,  1.0889e-01,  2.6578e+00, -1.4261e+00,\n",
      "         1.1044e+00,  5.2517e+00,  9.9180e+00,  1.4349e+01,  1.1879e+01,\n",
      "         5.9933e+00,  1.0187e+01, -3.5622e-01,  8.2944e+00,  6.0045e+00,\n",
      "         6.8180e-01,  4.1578e-01,  2.0737e+00, -5.6413e-01,  4.7995e+00,\n",
      "         9.0061e+00,  1.7071e+00,  2.3002e+00,  4.6022e+00,  3.6505e+00,\n",
      "        -9.0273e-01,  8.5786e-01,  4.4727e+00,  2.8649e+00,  9.2457e+00,\n",
      "         3.4102e+00,  3.9917e+00,  3.7679e+00,  7.0331e+00,  3.9104e+00,\n",
      "         4.3318e+00, -3.0546e-01,  3.9032e+00,  1.5516e-01,  1.4058e+00,\n",
      "        -2.0541e+00, -1.2255e+00,  1.4593e+00, -1.4634e+00, -1.5779e+00,\n",
      "        -1.3263e+00,  9.0113e-02, -2.6254e+00, -1.4612e-01, -7.6091e-01,\n",
      "        -5.3533e+00, -3.6175e+00, -2.3206e+00, -1.6837e+00, -3.7526e+00,\n",
      "        -3.8897e+00, -7.9057e-01, -1.5147e+00, -5.7233e+00, -2.8712e+00,\n",
      "        -7.2140e-01, -4.1371e-01, -7.2044e-01,  4.1286e-02, -1.0206e+00,\n",
      "        -3.3005e+00, -3.5724e+00, -1.9925e+00, -1.6717e+00, -5.8984e+00,\n",
      "        -5.3597e+00, -3.9811e+00, -3.6555e+00, -4.1505e+00, -2.9052e+00,\n",
      "        -1.0423e+00, -2.6901e+00, -1.9043e+00, -2.3410e+00, -6.1690e-01,\n",
      "         3.5220e+00,  6.2731e+00,  8.5439e+00,  5.0713e+00,  1.8232e+00,\n",
      "         4.6730e+00,  8.4174e-01, -1.7772e-02,  3.3705e+00, -1.0986e-01,\n",
      "        -2.4651e+00,  2.4176e+00, -5.1544e-01, -3.5527e+00, -3.5435e+00,\n",
      "         1.9493e-01, -1.3833e+00, -2.6136e+00,  2.4901e+00, -2.4007e+00,\n",
      "        -1.1922e+00, -4.9962e+00, -3.3103e+00, -4.2535e-01, -3.7342e+00,\n",
      "         5.3818e+00,  3.4589e+00,  1.0388e+00,  3.7677e+00,  4.1486e+00,\n",
      "        -6.7923e-01,  2.9729e+00, -2.6695e-01,  8.1169e-01, -1.7033e+00,\n",
      "        -2.0492e+00, -2.9611e+00, -3.2779e+00, -8.9598e-01, -3.3110e+00,\n",
      "        -3.3983e-01,  1.2493e+00, -8.9946e-01,  1.4518e+00,  9.4620e-01,\n",
      "        -2.0537e+00, -4.4116e+00,  2.2771e+00, -6.8451e-01, -8.9227e-01,\n",
      "         1.5176e+00, -3.8468e-01, -4.0643e-01,  9.6418e-01,  1.2567e+00,\n",
      "        -4.6659e+00, -6.3832e+00,  7.3633e-01, -1.3410e+00, -6.4761e-02,\n",
      "        -2.0370e+00,  3.7118e-01, -3.5582e+00, -1.9910e+00, -1.8657e+00,\n",
      "         1.3284e+00, -3.7591e+00, -2.9668e+00, -1.0196e+00, -1.9410e+00,\n",
      "        -3.0024e+00,  2.2402e-01,  1.7240e+00, -2.3679e+00, -1.2700e+00,\n",
      "        -1.0095e+00, -4.0593e+00,  1.9846e-02,  1.4469e+00,  6.9130e-02,\n",
      "        -3.4579e+00,  1.0540e+00,  3.5123e+00,  6.4476e-01, -1.4384e+00,\n",
      "        -2.3967e-01, -3.5266e+00, -9.4285e-01, -1.0286e+00,  3.3508e-01,\n",
      "         2.0511e-01, -8.7318e-02,  2.2660e-01, -9.6315e-01, -1.7716e+00,\n",
      "         6.4707e-01, -3.3329e-02,  4.2797e+00,  5.3268e+00,  2.2392e+00,\n",
      "        -3.5652e+00,  1.1825e+00,  4.2800e-02, -2.6242e+00,  1.1232e-01,\n",
      "         1.2852e+00,  1.5742e+00,  1.2006e+00, -2.4423e+00, -8.4675e-01,\n",
      "         2.8635e+00,  2.8959e-01, -5.9263e-01, -9.2986e-01,  1.4147e+00,\n",
      "        -1.0869e+00,  8.0699e-01,  2.6028e+00, -1.2705e+00, -7.7062e-01,\n",
      "         2.2781e+00, -1.4846e+00,  5.9643e-01, -9.0514e-01, -2.9385e+00,\n",
      "        -1.4975e+00,  2.7347e+00,  2.9151e+00, -2.5206e-01, -1.1142e+00,\n",
      "         2.3851e+00,  7.6144e-01,  5.4308e+00,  4.6903e+00, -1.2780e-01,\n",
      "        -8.0481e-01, -3.1204e+00, -4.0460e+00,  6.5959e-01,  2.0473e+00,\n",
      "         2.7161e+00,  2.0456e+00,  1.9894e+00, -1.4321e+00, -2.0452e+00,\n",
      "        -1.6197e+00, -7.0652e-01,  6.1669e-01,  2.5883e+00,  2.1854e+00,\n",
      "        -6.2268e-01, -1.9585e+00, -8.5994e-01,  7.1832e-01,  2.1846e+00,\n",
      "         2.9351e-01, -2.9151e+00,  4.7538e-01,  2.0823e+00,  4.0771e+00,\n",
      "        -2.4124e-01,  1.3029e+00, -4.9873e-01, -3.4026e-01,  6.6493e-01,\n",
      "        -1.1426e+00,  1.2239e+00, -1.6477e+00,  1.0247e+00, -1.1734e-02,\n",
      "        -3.8739e+00,  1.3966e+00,  3.1095e+00,  2.1778e+00,  9.4508e-03,\n",
      "         8.3204e-01,  6.4121e-01,  6.4727e-01,  1.8230e+00, -2.7591e+00,\n",
      "        -3.6885e+00,  1.3738e+00,  9.3979e-02,  8.2756e-01, -1.5154e+00,\n",
      "         2.2729e+00,  1.3410e-01, -2.9052e+00, -1.5847e-01,  2.5877e+00,\n",
      "        -1.2423e+00, -1.2836e+00,  5.8333e+00,  1.6887e+00, -2.0524e-01,\n",
      "        -1.0216e+00, -2.4560e+00, -5.1058e-01, -5.3143e-01, -4.5704e-01,\n",
      "         2.6477e-01, -2.9203e+00, -3.0220e+00,  2.3095e-01,  1.5559e+00,\n",
      "        -1.2820e-01, -1.8135e+00,  2.3484e+00, -3.3163e+00,  4.9580e+00,\n",
      "        -4.9515e+00, -7.4255e-01,  2.1618e+00,  7.6496e-01,  2.0683e+00,\n",
      "         1.6292e+00, -1.1905e-01, -4.3685e+00, -2.1957e+00, -3.0423e-01,\n",
      "        -3.8264e+00, -1.6591e+00,  4.3491e+00,  2.6929e-01, -3.5530e-01,\n",
      "        -2.6206e-01, -4.9771e-01,  2.2981e+00,  2.2476e+00,  8.4907e-01,\n",
      "        -9.5811e-01, -1.5191e-02,  2.0721e-01,  6.2752e-01, -2.0700e+00,\n",
      "        -2.8897e+00,  1.5538e+00,  7.2848e-01, -1.0269e+00,  3.7640e-02,\n",
      "        -1.0341e+00, -6.6757e-02,  9.0194e-02,  2.3256e+00,  2.5570e+00,\n",
      "         1.4790e+00, -2.1418e+00,  8.2613e-01,  9.1093e-01,  5.9269e-01,\n",
      "         1.4141e-01,  1.2912e+00, -1.2450e+00, -3.0307e+00,  1.3504e+00,\n",
      "         6.4917e-01,  1.0277e+00,  1.3770e+00,  1.0389e+00,  4.7428e-01,\n",
      "         5.2034e-01, -8.7671e-01, -1.4968e+00, -1.1777e+00,  1.1036e+00,\n",
      "        -2.2554e+00,  2.1375e+00,  9.7494e-01, -1.0108e+00, -1.6566e+00,\n",
      "         2.1618e-03,  1.6680e+00, -2.1605e+00, -2.3786e+00, -3.4123e+00,\n",
      "        -5.3376e-01,  1.9234e-01, -8.0424e-01,  1.6573e+00, -5.1894e-01,\n",
      "        -1.6282e-01, -8.9661e-01, -4.5872e+00,  1.4680e+00, -4.5170e-01,\n",
      "         1.2414e+00,  6.0595e-01, -3.8610e-01, -1.7395e+00, -1.5705e+00,\n",
      "         9.3813e-01,  4.2481e+00,  1.2018e+00, -2.3926e-01, -3.2441e+00,\n",
      "        -1.0988e+00, -9.5735e-02,  1.8680e+00,  1.1256e+00,  2.0857e+00,\n",
      "         9.5022e-01,  1.8395e+00,  2.5334e-01,  1.8772e-01, -1.2825e+00,\n",
      "        -6.7001e-01,  2.0543e+00,  1.4351e+00, -2.2930e-01, -8.0983e-01,\n",
      "         1.9751e+00,  1.1948e+00, -8.6681e-01, -6.6737e-01,  5.4154e-01,\n",
      "        -4.6361e-01,  2.6533e+00, -1.3025e+00, -1.6551e+00, -1.3140e+00,\n",
      "         3.2753e-01, -5.4466e-01,  1.6653e+00,  4.5679e+00, -2.3596e+00,\n",
      "         1.2472e+00,  1.1985e+00,  4.0662e+00, -2.4993e-03, -1.1256e+00,\n",
      "         1.3113e+00, -3.5844e-01, -6.1484e-01, -4.0013e+00,  1.6354e+00,\n",
      "        -1.0259e+00, -4.5651e-01,  5.7432e-01, -3.4964e+00, -1.1116e-01,\n",
      "        -4.9753e-01,  6.6538e-01, -6.2708e-01,  1.0448e+00,  3.0515e+00,\n",
      "        -3.1692e-01,  2.7604e+00,  6.2907e-01, -1.8008e+00, -2.0621e+00,\n",
      "         6.7936e-01,  9.9368e-02, -1.0732e+00,  3.0311e-01, -1.7549e+00,\n",
      "         1.1891e+00, -2.5658e+00, -2.0417e+00, -2.0310e-02, -6.6381e-01,\n",
      "        -1.3267e+00, -1.5515e+00,  1.4484e+00,  4.8665e-01, -2.8404e-01,\n",
      "         2.0569e+00,  1.8877e+00, -4.4666e-01, -6.0067e-01,  1.4969e+00,\n",
      "         4.2770e+00,  5.0480e-02, -3.9794e+00,  1.6875e+00,  1.1601e-01,\n",
      "        -2.1964e+00, -1.4540e+00,  6.2882e-01, -6.8122e-02, -1.1178e-01,\n",
      "        -2.6757e+00, -1.8709e+00, -3.3278e-02, -1.3882e+00, -5.7889e-01,\n",
      "        -2.6317e+00,  2.9095e+00,  7.7750e-01,  1.2120e+00,  1.8175e+00,\n",
      "        -1.2168e+00,  1.0038e+00,  2.1959e+00,  3.8340e+00, -1.8396e+00,\n",
      "         5.7705e-01, -4.0013e+00, -2.7974e-01,  2.3995e+00, -1.1584e+00,\n",
      "         7.8112e-01,  4.9273e+00, -1.8752e+00,  4.6019e+00, -4.2364e+00,\n",
      "         3.0356e-01, -2.9248e+00, -4.0923e-01, -2.6735e-01, -3.2818e+00,\n",
      "         4.9736e-02, -1.1436e+00,  1.9028e+00, -3.3808e+00,  3.5583e+00,\n",
      "        -5.8205e-01, -2.5741e-01,  2.5958e+00,  4.8656e-01,  3.4066e+00,\n",
      "         1.9533e+00,  4.3997e+00,  3.0976e+00,  1.8686e+00,  2.3232e+00,\n",
      "        -1.7744e+00,  4.5964e+00, -3.1526e-01,  2.5534e+00, -4.2597e-01,\n",
      "         1.1676e+00,  3.7421e+00, -3.3211e+00,  2.9848e+00,  2.4001e+00,\n",
      "         1.8138e+00,  6.2540e-01, -3.0627e+00,  1.3818e+00,  2.3651e-01,\n",
      "         4.5030e-01, -5.2303e-01, -6.3053e-01, -2.3103e+00, -9.1422e-02,\n",
      "         4.7515e-01, -4.4487e-01,  3.7741e-01, -1.8152e+00, -1.6175e+00,\n",
      "        -3.7013e-01, -5.8069e-01,  1.7530e+00,  7.7993e-01, -7.8516e-02,\n",
      "         1.5508e-02, -2.9961e+00,  1.5078e+00, -1.9644e+00, -2.1431e+00,\n",
      "         8.6377e-01,  1.3713e+00,  4.8443e+00,  1.1945e+00, -4.5833e-02,\n",
      "        -6.8948e-01, -2.3969e+00,  2.2506e+00, -2.8840e+00,  2.9678e-01,\n",
      "        -2.6206e-02, -1.6353e+00,  5.4359e-01,  7.9373e-01, -4.7254e-01,\n",
      "         3.3794e+00,  3.1471e-01, -4.7297e-01,  4.8753e-01, -2.1324e+00,\n",
      "        -1.1889e+00,  2.8763e+00, -2.5234e+00,  6.7766e-01,  4.2497e-01,\n",
      "        -1.5071e-01, -2.3746e-01,  2.6084e+00,  2.2631e+00, -1.3219e+00,\n",
      "        -1.4642e+00, -1.7742e-01,  2.8666e-02,  3.6176e+00,  1.2021e+00,\n",
      "         1.5262e+00,  1.1375e+00,  1.3798e+00,  1.2300e+00, -3.1643e+00,\n",
      "         1.8676e+00,  5.6669e-01,  3.5534e-01,  3.7592e+00, -7.5708e-01,\n",
      "         1.4573e+00,  9.2806e-01,  1.7963e+00,  1.3085e+00,  3.3143e-01,\n",
      "         2.5049e+00,  1.2414e-01, -1.9802e+00, -1.9173e+00,  2.2396e+00,\n",
      "         1.7752e+00, -1.0185e+00,  1.1142e+00, -5.6732e-01,  8.5282e-01,\n",
      "        -9.1948e-01,  1.7160e+00,  5.5459e+00, -1.1383e+00, -1.0506e+00,\n",
      "         9.4892e-01, -1.1270e+00, -4.1223e+00, -1.5021e+00, -2.4440e+00,\n",
      "        -2.2470e+00,  2.9617e-01,  5.9254e-02, -6.7028e-02, -3.7118e-01,\n",
      "        -3.9489e+00, -2.5805e-01,  1.0714e+00,  2.7642e-01,  1.3175e-01,\n",
      "         2.9845e+00,  1.5624e+00, -1.3119e+00, -3.4244e+00, -4.8180e+00,\n",
      "        -7.1618e-02,  2.9695e+00, -1.4996e+00, -1.4052e+00,  3.6904e+00,\n",
      "         2.2548e+00,  2.3318e-01,  3.8367e+00, -5.6721e-01, -2.9730e+00,\n",
      "        -1.8200e+00, -2.4849e-01, -5.4816e+00, -1.7667e+00, -1.3183e-01,\n",
      "        -3.1745e+00, -1.5823e+00, -6.3336e-01, -4.9233e-01, -1.8396e+00,\n",
      "         1.0520e+00,  1.6701e+00,  1.8454e+00,  4.0347e+00,  1.3916e+00,\n",
      "        -3.2765e+00, -4.5980e-01,  1.0720e+00, -3.8485e-01,  2.3624e+00,\n",
      "        -5.1498e-02, -1.5342e-01,  1.7896e+00,  8.5419e-01,  6.7955e-01,\n",
      "         7.2410e-01,  7.1604e-01,  3.4530e+00,  3.4272e-01, -1.2744e+00,\n",
      "        -1.6029e+00, -1.1189e-01, -5.0279e+00, -9.6868e-01, -2.9694e-01,\n",
      "        -5.2332e-01, -2.2457e+00, -3.0345e+00, -1.7821e-01, -1.8209e+00,\n",
      "        -2.9185e+00, -5.3196e+00, -4.1614e-01, -1.1463e+00,  4.0227e+00,\n",
      "         1.6177e+00, -7.2444e-01,  2.2105e+00, -3.8580e+00, -2.6037e-01,\n",
      "         1.3896e+00,  2.0437e+00,  1.4341e+00, -5.5741e-01,  8.4965e-01,\n",
      "         1.2590e+00, -2.3672e+00,  5.4990e-01,  2.3602e-01, -2.1981e+00,\n",
      "        -3.3608e+00, -2.3926e+00, -1.7003e+00,  2.6105e+00,  1.6129e+00,\n",
      "        -3.3497e-01, -4.8806e-01, -3.1887e+00, -4.0140e-01, -1.3856e+00,\n",
      "        -3.3772e-01, -1.3071e+00,  3.4265e-01,  2.9913e+00, -1.0328e+00,\n",
      "        -5.0624e-01,  7.2033e-01, -1.3757e+00, -2.2462e+00, -3.8978e+00,\n",
      "        -2.0316e+00,  1.1214e+00, -4.8799e+00,  3.3041e-01,  1.5113e+00,\n",
      "         1.1555e+00,  2.0594e+00,  5.9396e-01, -3.9946e+00, -7.1919e-01,\n",
      "         2.9405e+00, -1.7745e+00,  1.8117e+00, -2.9002e-01, -1.3358e+00,\n",
      "         4.0620e-01,  1.4948e-02, -1.6891e-01, -2.5009e+00, -2.3665e-01,\n",
      "        -5.1094e-01, -7.8531e-01,  1.9885e+00, -2.5693e-01, -2.7400e+00,\n",
      "         6.9324e-01, -1.7623e+00, -5.0880e-01, -6.8333e+00, -4.1541e+00,\n",
      "        -2.5820e+00, -1.4276e+00, -3.0733e+00,  1.6649e+00,  3.3375e+00],\n",
      "       device='cuda:0')\n",
      "tensor([3.9943e-06, 8.6193e-08, 5.2436e-08, 2.5163e-08, 4.5210e-08, 1.2973e-06,\n",
      "        9.8293e-08, 1.9543e-05, 2.8833e-04, 1.3301e-07, 5.6500e-10, 1.7000e-08,\n",
      "        1.6949e-10, 5.6399e-09, 1.7226e-09, 4.5992e-09, 6.8660e-08, 3.4116e-07,\n",
      "        1.3555e-07, 4.5504e-09, 1.8155e-08, 3.7286e-08, 4.2701e-08, 1.3213e-07,\n",
      "        1.8953e-08, 1.1787e-07, 1.4773e-07, 7.3969e-07, 9.7916e-08, 2.3935e-06,\n",
      "        6.4642e-07, 2.6120e-07, 3.6290e-07, 1.0691e-08, 1.0440e-07, 2.6985e-08,\n",
      "        2.7762e-07, 4.4694e-08, 3.4863e-07, 1.7520e-06, 1.3937e-07, 3.4508e-08,\n",
      "        2.1968e-08, 5.1549e-08, 3.1283e-07, 1.3735e-07, 1.1207e-06, 6.3071e-08,\n",
      "        2.5103e-07, 4.4780e-07, 7.9676e-07, 8.7148e-08, 2.2443e-07, 1.6228e-07,\n",
      "        2.8596e-07, 2.6289e-08, 7.0604e-08, 3.2040e-08, 2.6664e-07, 9.1000e-08,\n",
      "        1.8817e-06, 7.2455e-09, 1.1176e-07, 5.1165e-09, 1.8556e-08, 8.8835e-09,\n",
      "        5.7093e-07, 6.6705e-08, 2.3144e-07, 7.1558e-09, 9.9799e-09, 1.8915e-07,\n",
      "        5.7205e-08, 1.3844e-08, 4.1449e-08, 1.9146e-08, 2.1013e-08, 3.3350e-08,\n",
      "        3.4498e-07, 1.7977e-06, 7.9489e-08, 2.4324e-07, 8.9943e-07, 1.4087e-06,\n",
      "        9.8630e-07, 5.7445e-08, 2.1215e-07, 1.3597e-07, 2.5551e-08, 6.6848e-06,\n",
      "        2.2232e-08, 9.6018e-09, 2.9746e-09, 3.3010e-08, 6.9067e-09, 1.5449e-09,\n",
      "        1.1293e-07, 1.7323e-08, 2.9284e-09, 5.5628e-07, 9.2710e-07, 1.0609e-08,\n",
      "        2.6538e-07, 1.0671e-08, 2.0363e-03, 3.9329e-07, 2.3439e-06, 1.8879e-08,\n",
      "        1.3189e-07, 6.2909e-09, 7.3033e-08, 5.6564e-09, 3.5938e-08, 3.0200e-07,\n",
      "        9.4877e-07, 1.6042e-07, 6.6813e-08, 2.4674e-08, 5.1944e-07, 4.6808e-07,\n",
      "        3.3368e-09, 3.4053e-07, 5.2064e-07, 5.0037e-07, 1.4085e-06, 1.1464e-08,\n",
      "        5.0075e-08, 1.5803e-07, 1.2608e-08, 1.7703e-07, 1.0704e-08, 3.5518e-08,\n",
      "        1.0987e-06, 3.8411e-09, 4.0738e-07, 1.1096e-08, 2.9740e-08, 8.5120e-09,\n",
      "        3.0862e-08, 2.4045e-10, 8.7016e-10, 1.1461e-08, 4.0427e-09, 2.5314e-08,\n",
      "        1.5154e-07, 1.5517e-07, 7.3519e-07, 5.5854e-08, 4.9636e-08, 9.1279e-08,\n",
      "        4.4297e-08, 2.2812e-04, 2.7158e-04, 2.9769e-05, 1.5594e-04, 1.9609e-06,\n",
      "        6.7412e-07, 1.4899e-03, 2.3570e-06, 4.7830e-07, 4.9988e-07, 2.2933e-07,\n",
      "        8.0039e-07, 1.0294e-07, 4.9207e-08, 1.2711e-08, 2.5368e-07, 5.0894e-08,\n",
      "        5.6954e-07, 4.8037e-05, 1.4516e-05, 5.2124e-07, 1.0251e-07, 7.3136e-05,\n",
      "        1.6771e-04, 2.2683e-06, 6.2307e-08, 5.4204e-06, 4.0695e-08, 1.7680e-06,\n",
      "        3.3461e-06, 2.9749e-08, 1.7663e-06, 6.4556e-07, 6.0739e-06, 3.7897e-05,\n",
      "        1.3622e-04, 2.6355e-07, 1.3853e-05, 3.6733e-07, 5.0530e-06, 1.2714e-07,\n",
      "        1.1808e-04, 4.4263e-05, 6.3083e-07, 1.5313e-06, 4.2834e-07, 1.4788e-06,\n",
      "        5.1651e-07, 3.3076e-04, 5.7106e-06, 7.9150e-07, 3.4666e-07, 4.8831e-03,\n",
      "        2.5037e-06, 1.8097e-06, 5.9195e-07, 4.6503e-05, 4.3201e-06, 6.0581e-07,\n",
      "        4.3555e-08, 8.8456e-07, 9.7903e-06, 2.8158e-07, 1.3247e-07, 8.0358e-06,\n",
      "        3.4618e-06, 3.8015e-06, 1.0457e-06, 2.6235e-06, 3.3976e-06, 2.2005e-07,\n",
      "        6.5418e-04, 3.9724e-03, 1.4538e-03, 5.1063e-06, 2.0702e-05, 1.5095e-04,\n",
      "        2.1846e-05, 3.3850e-04, 8.0965e-03, 1.0820e-02, 6.6846e-03, 5.2922e-06,\n",
      "        2.9343e-07, 8.0351e-05, 8.6266e-07, 2.2876e-06, 1.7507e-06, 1.7084e-05,\n",
      "        6.1822e-06, 2.1466e-06, 2.1502e-07, 3.1156e-08, 1.1500e-06, 2.7127e-07,\n",
      "        3.2203e-07, 1.2676e-05, 7.7375e-03, 3.9094e-03, 5.1042e-03, 1.9734e-06,\n",
      "        5.4256e-07, 6.9409e-06, 1.1690e-07, 1.4683e-06, 9.2889e-05, 9.8737e-03,\n",
      "        8.2979e-01, 7.0151e-02, 1.9499e-04, 1.2921e-02, 3.4077e-07, 1.9470e-03,\n",
      "        1.9718e-04, 9.6220e-07, 7.3745e-07, 3.8706e-06, 2.7680e-07, 5.9094e-05,\n",
      "        3.9671e-03, 2.6825e-06, 4.8543e-06, 4.8517e-05, 1.8731e-05, 1.9729e-07,\n",
      "        1.1474e-06, 4.2621e-05, 8.5384e-06, 5.0411e-03, 1.4730e-05, 2.6348e-05,\n",
      "        2.1064e-05, 5.5159e-04, 2.4289e-05, 3.7019e-05, 3.5851e-07, 2.4116e-05,\n",
      "        5.6826e-07, 1.9847e-06, 6.2383e-08, 1.4287e-07, 2.0938e-06, 1.1262e-07,\n",
      "        1.0044e-07, 1.2916e-07, 5.3247e-07, 3.5233e-08, 4.2044e-07, 2.2735e-07,\n",
      "        2.3028e-09, 1.3064e-08, 4.7788e-08, 9.0355e-08, 1.1414e-08, 9.9513e-09,\n",
      "        2.2071e-07, 1.0698e-07, 1.5906e-09, 2.7556e-08, 2.3652e-07, 3.2173e-07,\n",
      "        2.3674e-07, 5.0710e-07, 1.7536e-07, 1.7938e-08, 1.3668e-08, 6.6346e-08,\n",
      "        9.1447e-08, 1.3351e-09, 2.2880e-09, 9.0824e-09, 1.2578e-08, 7.6666e-09,\n",
      "        2.6636e-08, 1.7159e-07, 3.3026e-08, 7.2464e-08, 4.6825e-08, 2.6257e-07,\n",
      "        1.6472e-05, 2.5794e-04, 2.4988e-03, 7.7555e-05, 3.0126e-06, 5.2076e-05,\n",
      "        1.1291e-06, 4.7802e-07, 1.4157e-05, 4.3596e-07, 4.1362e-08, 5.4589e-06,\n",
      "        2.9061e-07, 1.3939e-08, 1.4068e-08, 5.9131e-07, 1.2201e-07, 3.5651e-08,\n",
      "        5.8696e-06, 4.4113e-08, 1.4771e-07, 3.2912e-09, 1.7763e-08, 3.1801e-07,\n",
      "        1.1626e-08, 1.0579e-04, 1.5464e-05, 1.3751e-06, 2.1060e-05, 3.0823e-05,\n",
      "        2.4670e-07, 9.5122e-06, 3.7258e-07, 1.0957e-06, 8.8601e-08, 6.2689e-08,\n",
      "        2.5187e-08, 1.8349e-08, 1.9863e-07, 1.7751e-08, 3.4640e-07, 1.6972e-06,\n",
      "        1.9794e-07, 2.0781e-06, 1.2534e-06, 6.2411e-08, 5.9050e-09, 4.7434e-06,\n",
      "        2.4540e-07, 1.9937e-07, 2.2194e-06, 3.3121e-07, 3.2408e-07, 1.2761e-06,\n",
      "        1.7098e-06, 4.5792e-09, 8.2220e-10, 1.0161e-06, 1.2728e-07, 4.5607e-07,\n",
      "        6.3463e-08, 7.0528e-07, 1.3862e-08, 6.6445e-08, 7.5320e-08, 1.8368e-06,\n",
      "        1.1340e-08, 2.5043e-08, 1.7553e-07, 6.9858e-08, 2.4169e-08, 6.0877e-07,\n",
      "        2.7282e-06, 4.5581e-08, 1.3665e-07, 1.7731e-07, 8.3994e-09, 4.9634e-07,\n",
      "        2.0679e-06, 5.2142e-07, 1.5325e-08, 1.3961e-06, 1.6313e-05, 9.2720e-07,\n",
      "        1.1548e-07, 3.8289e-07, 1.4309e-08, 1.8953e-07, 1.7396e-07, 6.8028e-07,\n",
      "        5.9736e-07, 4.4590e-07, 6.1034e-07, 1.8573e-07, 8.2753e-08, 9.2935e-07,\n",
      "        4.7064e-07, 3.5141e-05, 1.0013e-04, 4.5670e-06, 1.3766e-08, 1.5876e-06,\n",
      "        5.0787e-07, 3.5276e-08, 5.4443e-07, 1.7592e-06, 2.3488e-06, 1.6165e-06,\n",
      "        4.2312e-08, 2.0865e-07, 8.5266e-06, 6.5002e-07, 2.6902e-07, 1.9201e-07,\n",
      "        2.0024e-06, 1.6411e-07, 1.0905e-06, 6.5695e-06, 1.3658e-07, 2.2516e-07,\n",
      "        4.7480e-06, 1.1025e-07, 8.8346e-07, 1.9682e-07, 2.5762e-08, 1.0885e-07,\n",
      "        7.4958e-06, 8.9777e-06, 3.7818e-07, 1.5969e-07, 5.2845e-06, 1.0420e-06,\n",
      "        1.1110e-04, 5.2981e-05, 4.2821e-07, 2.1759e-07, 2.1478e-08, 8.5112e-09,\n",
      "        9.4106e-07, 3.7697e-06, 7.3581e-06, 3.7630e-06, 3.5577e-06, 1.1620e-07,\n",
      "        6.2939e-08, 9.6319e-08, 2.4006e-07, 9.0154e-07, 6.4749e-06, 4.3278e-06,\n",
      "        2.6106e-07, 6.8644e-08, 2.0592e-07, 9.9798e-07, 4.3243e-06, 6.5258e-07,\n",
      "        2.6374e-08, 7.8273e-07, 3.9038e-06, 2.8696e-05, 3.8229e-07, 1.7907e-06,\n",
      "        2.9550e-07, 3.4625e-07, 9.4610e-07, 1.5522e-07, 1.6546e-06, 9.3661e-08,\n",
      "        1.3558e-06, 4.8091e-07, 1.0110e-08, 1.9664e-06, 1.0904e-05, 4.2951e-06,\n",
      "        4.9121e-07, 1.1182e-06, 9.2393e-07, 9.2953e-07, 3.0122e-06, 3.0824e-08,\n",
      "        1.2169e-08, 1.9222e-06, 5.3453e-07, 1.1132e-06, 1.0691e-07, 4.7234e-06,\n",
      "        5.5642e-07, 2.6635e-08, 4.1528e-07, 6.4710e-06, 1.4048e-07, 1.3480e-07,\n",
      "        1.6616e-04, 2.6335e-06, 3.9630e-07, 1.7518e-07, 4.1740e-08, 2.9202e-07,\n",
      "        2.8600e-07, 3.0809e-07, 6.3409e-07, 2.6236e-08, 2.3700e-08, 6.1300e-07,\n",
      "        2.3061e-06, 4.2804e-07, 7.9357e-08, 5.0938e-06, 1.7657e-08, 6.9246e-05,\n",
      "        3.4414e-09, 2.3157e-07, 4.2267e-06, 1.0456e-06, 3.8494e-06, 2.4814e-06,\n",
      "        4.3197e-07, 6.1654e-09, 5.4150e-08, 3.5895e-07, 1.0602e-08, 9.2599e-08,\n",
      "        3.7667e-05, 6.3696e-07, 3.4108e-07, 3.7441e-07, 2.9581e-07, 4.8441e-06,\n",
      "        4.6054e-06, 1.1374e-06, 1.8666e-07, 4.7925e-07, 5.9862e-07, 9.1136e-07,\n",
      "        6.1398e-08, 2.7050e-08, 2.3013e-06, 1.0082e-06, 1.7425e-07, 5.0525e-07,\n",
      "        1.7301e-07, 4.5516e-07, 5.3251e-07, 4.9791e-06, 6.2754e-06, 2.1354e-06,\n",
      "        5.7146e-08, 1.1116e-06, 1.2100e-06, 8.8016e-07, 5.6050e-07, 1.7697e-06,\n",
      "        1.4011e-07, 2.3493e-08, 1.8777e-06, 9.3131e-07, 1.3598e-06, 1.9283e-06,\n",
      "        1.3751e-06, 7.8187e-07, 8.1873e-07, 2.0249e-07, 1.0892e-07, 1.4986e-07,\n",
      "        1.4671e-06, 5.1008e-08, 4.1253e-06, 1.2900e-06, 1.7708e-07, 9.2838e-08,\n",
      "        4.8764e-07, 2.5797e-06, 5.6086e-08, 4.5095e-08, 1.6041e-08, 2.8533e-07,\n",
      "        5.8978e-07, 2.1771e-07, 2.5522e-06, 2.8959e-07, 4.1347e-07, 1.9850e-07,\n",
      "        4.9544e-09, 2.1120e-06, 3.0974e-07, 1.6837e-06, 8.9191e-07, 3.3074e-07,\n",
      "        8.5445e-08, 1.0118e-07, 1.2433e-06, 3.4048e-05, 1.6184e-06, 3.8305e-07,\n",
      "        1.8979e-08, 1.6216e-07, 4.4216e-07, 3.1508e-06, 1.4997e-06, 3.9171e-06,\n",
      "        1.2585e-06, 3.0623e-06, 6.2688e-07, 5.8707e-07, 1.3496e-07, 2.4899e-07,\n",
      "        3.7962e-06, 2.0437e-06, 3.8688e-07, 2.1650e-07, 3.5071e-06, 1.6072e-06,\n",
      "        2.0451e-07, 2.4965e-07, 8.3628e-07, 3.0607e-07, 6.9096e-06, 1.3229e-07,\n",
      "        9.2978e-08, 1.3077e-07, 6.7516e-07, 2.8224e-07, 2.5727e-06, 4.6877e-05,\n",
      "        4.5963e-08, 1.6937e-06, 1.6130e-06, 2.8386e-05, 4.8537e-07, 1.5788e-07,\n",
      "        1.8056e-06, 3.4001e-07, 2.6311e-07, 8.9003e-09, 2.4970e-06, 1.7443e-07,\n",
      "        3.0825e-07, 8.6415e-07, 1.4747e-08, 4.3540e-07, 2.9586e-07, 9.4653e-07,\n",
      "        2.5991e-07, 1.3833e-06, 1.0290e-05, 3.5443e-07, 7.6911e-06, 9.1277e-07,\n",
      "        8.0365e-08, 6.1889e-08, 9.5985e-07, 5.3742e-07, 1.6636e-07, 6.5887e-07,\n",
      "        8.4147e-08, 1.5981e-06, 3.7399e-08, 6.3164e-08, 4.7680e-07, 2.5054e-07,\n",
      "        1.2911e-07, 1.0313e-07, 2.0711e-06, 7.9161e-07, 3.6627e-07, 3.8059e-06,\n",
      "        3.2134e-06, 3.1130e-07, 2.6687e-07, 2.1740e-06, 3.5047e-05, 5.1178e-07,\n",
      "        9.0979e-09, 2.6303e-06, 5.4644e-07, 5.4113e-08, 1.1368e-07, 9.1254e-07,\n",
      "        4.5454e-07, 4.3513e-07, 3.3507e-08, 7.4929e-08, 4.7066e-07, 1.2142e-07,\n",
      "        2.7274e-07, 3.5013e-08, 8.9279e-06, 1.0588e-06, 1.6350e-06, 2.9957e-06,\n",
      "        1.4412e-07, 1.3277e-06, 4.3734e-06, 2.2503e-05, 7.7313e-08, 8.6650e-07,\n",
      "        8.9006e-09, 3.6785e-07, 5.3613e-06, 1.5278e-07, 1.0627e-06, 6.7153e-05,\n",
      "        7.4603e-08, 4.8499e-05, 7.0356e-09, 6.5917e-07, 2.6117e-08, 3.2317e-07,\n",
      "        3.7244e-07, 1.8276e-08, 5.1140e-07, 1.5506e-07, 3.2626e-06, 1.6554e-08,\n",
      "        1.7080e-05, 2.7188e-07, 3.7616e-07, 6.5235e-06, 7.9154e-07, 1.4676e-05,\n",
      "        3.4313e-06, 3.9621e-05, 1.0775e-05, 3.1527e-06, 4.9673e-06, 8.2514e-08,\n",
      "        4.8235e-05, 3.5501e-07, 6.2527e-06, 3.1781e-07, 1.5640e-06, 2.0528e-05,\n",
      "        1.7573e-08, 9.6261e-06, 5.3644e-06, 2.9846e-06, 9.0942e-07, 2.2754e-08,\n",
      "        1.9377e-06, 6.1642e-07, 7.6335e-07, 2.8841e-07, 2.5901e-07, 4.8283e-08,\n",
      "        4.4408e-07, 7.8256e-07, 3.1186e-07, 7.0969e-07, 7.9221e-08, 9.6534e-08,\n",
      "        3.3606e-07, 2.7225e-07, 2.8087e-06, 1.0614e-06, 4.4984e-07, 4.9419e-07,\n",
      "        2.4321e-08, 2.1979e-06, 6.8238e-08, 5.7071e-08, 1.1542e-06, 1.9174e-06,\n",
      "        6.1804e-05, 1.6066e-06, 4.6479e-07, 2.4419e-07, 4.4277e-08, 4.6194e-06,\n",
      "        2.7205e-08, 6.5471e-07, 4.7400e-07, 9.4833e-08, 8.3799e-07, 1.0762e-06,\n",
      "        3.0335e-07, 1.4283e-05, 6.6656e-07, 3.0322e-07, 7.9231e-07, 5.7685e-08,\n",
      "        1.4820e-07, 8.6359e-06, 3.9018e-08, 9.5822e-07, 7.4426e-07, 4.1851e-07,\n",
      "        3.8374e-07, 6.6064e-06, 4.6775e-06, 1.2973e-07, 1.1253e-07, 4.0748e-07,\n",
      "        5.0074e-07, 1.8125e-05, 1.6189e-06, 2.2387e-06, 1.5176e-06, 1.9337e-06,\n",
      "        1.6647e-06, 2.0556e-08, 3.1495e-06, 8.5757e-07, 6.9419e-07, 2.0882e-05,\n",
      "        2.2823e-07, 2.0896e-06, 1.2309e-06, 2.9327e-06, 1.8006e-06, 6.7780e-07,\n",
      "        5.9567e-06, 5.5090e-07, 6.7169e-08, 7.1533e-08, 4.5689e-06, 2.8717e-06,\n",
      "        1.7573e-07, 1.4827e-06, 2.7591e-07, 1.1417e-06, 1.9401e-07, 2.7064e-06,\n",
      "        1.2465e-04, 1.5589e-07, 1.7017e-07, 1.2568e-06, 1.5766e-07, 7.8862e-09,\n",
      "        1.0834e-07, 4.2242e-08, 5.1439e-08, 6.5432e-07, 5.1629e-07, 4.5504e-07,\n",
      "        3.3571e-07, 9.3797e-09, 3.7591e-07, 1.4206e-06, 6.4152e-07, 5.5511e-07,\n",
      "        9.6235e-06, 2.3211e-06, 1.3104e-07, 1.5847e-08, 3.9330e-09, 4.5296e-07,\n",
      "        9.4799e-06, 1.0861e-07, 1.1937e-07, 1.9493e-05, 4.6388e-06, 6.1437e-07,\n",
      "        2.2565e-05, 2.7595e-07, 2.4889e-08, 7.8842e-08, 3.7953e-07, 2.0255e-09,\n",
      "        8.3154e-08, 4.2649e-07, 2.0347e-08, 9.9992e-08, 2.5828e-07, 2.9740e-07,\n",
      "        7.7310e-08, 1.3932e-06, 2.5851e-06, 3.0803e-06, 2.7506e-05, 1.9567e-06,\n",
      "        1.8374e-08, 3.0724e-07, 1.4214e-06, 3.3115e-07, 5.1659e-06, 4.6216e-07,\n",
      "        4.1738e-07, 2.9131e-06, 1.1432e-06, 9.6003e-07, 1.0038e-06, 9.9571e-07,\n",
      "        1.5374e-05, 6.8549e-07, 1.3606e-07, 9.7957e-08, 4.3508e-07, 3.1882e-09,\n",
      "        1.8470e-07, 3.6158e-07, 2.8833e-07, 5.1508e-08, 2.3404e-08, 4.0716e-07,\n",
      "        7.8767e-08, 2.6283e-08, 2.3816e-09, 3.2095e-07, 1.5464e-07, 2.7177e-05,\n",
      "        2.4532e-06, 2.3580e-07, 4.4379e-06, 1.0272e-08, 3.7505e-07, 1.9529e-06,\n",
      "        3.7560e-06, 2.0417e-06, 2.7866e-07, 1.1380e-06, 1.7137e-06, 4.5616e-08,\n",
      "        8.4330e-07, 6.1612e-07, 5.4020e-08, 1.6888e-08, 4.4470e-08, 8.8866e-08,\n",
      "        6.6208e-06, 2.4415e-06, 3.4809e-07, 2.9868e-07, 2.0060e-08, 3.2571e-07,\n",
      "        1.2173e-07, 3.4713e-07, 1.3167e-07, 6.8545e-07, 9.6885e-06, 1.7322e-07,\n",
      "        2.9329e-07, 1.0000e-06, 1.2294e-07, 5.1482e-08, 9.8710e-09, 6.3801e-08,\n",
      "        1.4934e-06, 3.6969e-09, 6.7710e-07, 2.2054e-06, 1.5452e-06, 3.8156e-06,\n",
      "        8.8128e-07, 8.9601e-09, 2.3704e-07, 9.2090e-06, 8.2513e-08, 2.9783e-06,\n",
      "        3.6409e-07, 1.2795e-07, 7.3042e-07, 4.9392e-07, 4.1096e-07, 3.9906e-08,\n",
      "        3.8405e-07, 2.9192e-07, 2.2187e-07, 3.5544e-06, 3.7634e-07, 3.1418e-08,\n",
      "        9.7327e-07, 8.3522e-08, 2.9254e-07, 5.2422e-10, 7.6397e-09, 3.6795e-08,\n",
      "        1.1673e-07, 2.2514e-08, 2.5718e-06, 1.3696e-05], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "input_image = Image.open(filename)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "# Tensor of shape 1000, with confidence scores over ImageNet's 1000 classes\n",
    "print(output[0])\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "print(probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-29 15:42:15--  https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10472 (10K) [text/plain]\n",
      "Saving to: ‘imagenet_classes.txt’\n",
      "\n",
      "imagenet_classes.tx 100%[===================>]  10.23K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2024-12-29 15:42:15 (786 KB/s) - ‘imagenet_classes.txt’ saved [10472/10472]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download ImageNet labels\n",
    "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samoyed 0.8297895193099976\n",
      "Pomeranian 0.07015100866556168\n",
      "keeshond 0.012921061366796494\n",
      "collie 0.010819987393915653\n",
      "Great Pyrenees 0.009873730130493641\n"
     ]
    }
   ],
   "source": [
    "# Read the categories\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "# Show top categories per image\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsupervised",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
